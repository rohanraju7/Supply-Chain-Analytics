# -*- coding: utf-8 -*-
"""SCM-Final-Project-Part-2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1G715tTcVRJCC2v7tyr2pXhBIUFvTv8mL
"""

import warnings
warnings.filterwarnings('ignore')

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import seaborn as sns
import statsmodels.api as sm
from statsmodels.graphics.tsaplots import plot_acf
from statsmodels.tsa.arima.model import ARIMA
from statsmodels.tsa.seasonal import seasonal_decompose, STL
from statsmodels.tsa.holtwinters import ExponentialSmoothing
from sklearn.metrics import mean_squared_error

def clean_excel_df(df):
    new_header = df.iloc[0]
    df = df[1:]
    df.columns = new_header
    df['Date'] = pd.to_datetime(df['Date'])
    df['CoughX'] = df['CoughX'].astype(float)
    df['InfeX'] = df['InfeX'].astype(float)
    df['year'] = df['Date'].dt.year
    df['month'] = df['Date'].dt.month
    df['month_count'] = 1
    df['month_count'] = df['month_count'].cumsum()
    return df

data_part1 = pd.read_excel('Rohan Sindhoora Demand_Data_2017-2018.xlsx')
data_part1 = clean_excel_df(data_part1)
data_part1.head()

data_part1.columns

data_part2 = pd.read_excel('Demand_Data_2017-2019.xlsx')
data_part2 = clean_excel_df(data_part2)
#data_part2.columns = data_part2.columns
data_part2.columns = ['Date', 'CoughX', 'InfeX', 'CoughX - Avg', 'InfeX - Avg',
                      'CoughX - Exp Smoothing', 'InfeX - Exp Smoothing',
                      'year', 'month', 'month_count']
data_part2.head()

"""### Accuracy of Predictions From Part 1"""

def print_accuracy(data_part1, data_part2, col, pred_type):
    pred_2019 = data_part1[data_part1['year']==2019]
    actual_2019 = data_part2[data_part2['year']==2019]

    plt.figure(figsize=(15,5))
    plt.grid()
    plt.title(f'{col} Predicted Vs. Actual')
    plt.plot(pred_2019['month'], pred_2019[f'{col} - {pred_type}'], color='green', label='Predicted')
    plt.plot(actual_2019['month'], actual_2019[col], color='blue', label='Actual')
    plt.legend()

    mse = np.sqrt(mean_squared_error(actual_2019[col], pred_2019[f'{col} - {pred_type}']))
    mape = np.round(np.mean(
            np.abs(actual_2019[col] - pred_2019[f'{col} - {pred_type}']) / actual_2019[col]) * 100, 2)

    print('mse: ', mse)
    print('mape: ', mape)

    return

print_accuracy(data_part1, data_part2, 'CoughX', 'Exp Smoothing')

print_accuracy(data_part1, data_part2, 'InfeX', 'Exp Smoothing')

"""#### Simple Average Predictions"""

data_part1['CoughX_shifted_1y'] = data_part1['CoughX'].shift(12)
data_part1['CoughX_shifted_2y'] = data_part1['CoughX'].shift(24)
data_part1['InfeX_shifted_1y'] = data_part1['InfeX'].shift(12)
data_part1['InfeX_shifted_2y'] = data_part1['InfeX'].shift(24)
data_part1['CoughX - Average'] = (data_part1['CoughX_shifted_1y'] + data_part1['CoughX_shifted_2y']) / 2
data_part1['InfeX - Average'] = (data_part1['InfeX_shifted_1y'] + data_part1['InfeX_shifted_2y']) / 2

print_accuracy(data_part1, data_part2, 'CoughX', 'Average')

print_accuracy(data_part1, data_part2, 'InfeX', 'Average')

data_part2['CoughX_shifted_1y'] = data_part2['CoughX'].shift(12)
data_part2['CoughX_shifted_2y'] = data_part2['CoughX'].shift(24)
data_part2['CoughX_shifted_3y'] = data_part2['CoughX'].shift(36)
data_part2['CoughX - Average'] = (data_part2['CoughX_shifted_1y'] +
                                  data_part2['CoughX_shifted_2y'] +
                                  data_part2['CoughX_shifted_3y']) / 3
data_part2['CoughX - Average']

data_part2['InfeX_shifted_1y'] = data_part2['InfeX_outliers_removed'].shift(12)
data_part2['InfeX_shifted_2y'] = data_part2['InfeX_outliers_removed'].shift(24)
data_part2['InfeX_shifted_3y'] = data_part2['InfeX_outliers_removed'].shift(36)
data_part2['InfeX - Average'] = (data_part2['InfeX_shifted_1y'] +
                                  data_part2['InfeX_shifted_2y'] +
                                  data_part2['InfeX_shifted_3y']) / 3
data_part2['InfeX - Average']

print_accuracy(data_part1, data_part2, 'InfeX', 'Average')

"""#### Exponential Smoothing"""

grid_search_options_CoughX = []
alpha = [0.2, 0.4, 0.6, 0.8]
t_params = ['add', 'mul']
d_params = [True, False]
s_params = ['add', 'mul']
p_params = [12]
b_params = [True, False]
r_params = [True, False]
for a in alpha:
    for t in t_params:
        for d in d_params:
            for s in s_params:
                for p in p_params:
                    for b in b_params:
                        for r in r_params:
                            grid_search_options_CoughX.append([a,t,d,s,p,b,r])
len(grid_search_options_CoughX)

grid_search_options_InfeX = []
alpha = [0.2, 0.4, 0.6, 0.8]
t_params = [None]
d_params = [None]
s_params = [None]
p_params = [12]
b_params = [True, False]
r_params = [True, False]
for a in alpha:
    for t in t_params:
        for d in d_params:
            for s in s_params:
                for p in p_params:
                    for b in b_params:
                        for r in r_params:
                            grid_search_options_InfeX.append([a,t,d,s,p,b,r])
len(grid_search_options_InfeX)

pred_2019 = data_part1[data_part1['year']==2019]
actual_2019 = data_part2[data_part2['year']==2019]

min_mape = 100
min_mape_i = 0
i = 0
for [a,t,d,s,p,b,r] in grid_search_options_CoughX:
    i = i + 1

    if (t == None):
        model = ExponentialSmoothing(data_part1[data_part1['year'] < 2019]['CoughX'],
                                     trend=t, seasonal=s, seasonal_periods=p, use_boxcox=b)
    else:
        model = ExponentialSmoothing(data_part1[data_part1['year'] < 2019]['CoughX'],
                                     trend=t, damped=d, seasonal=s, seasonal_periods=p, use_boxcox=b)

    model_fit = model.fit(optimized=True, remove_bias=r, smoothing_level=a)

    pred_2019[f'CoughX_exp_smooth_{i}'] = model_fit.forecast(13)
    mape = np.round(np.mean(np.abs(actual_2019['CoughX'] - pred_2019[f'CoughX_exp_smooth_{i}']) / actual_2019['CoughX']) * 100, 2)
    if mape <= min_mape:
        min_mape = mape
        min_mape_i = i

plt.figure(figsize=(15,5))
plt.grid()
plt.title(f'CoughX Historical & Predicted Vs. Actual')

plt.plot(data_part1[data_part1['year'] == 2017]['month'], data_part1[data_part1['year'] == 2017]['CoughX'],
         label='Historical 2017', color='yellow')
plt.plot(data_part1[data_part1['year'] == 2018]['month'], data_part1[data_part1['year'] == 2018]['CoughX'],
         label='Historical 2018', color='yellow')
plt.plot(actual_2019['month'], actual_2019['CoughX'], label='Actual')

plt.plot(pred_2019['month'], pred_2019[f'CoughX_exp_smooth_{min_mape_i}'], label=f'Best MAPE = {min_mape}')

plt.legend()
print(grid_search_options_CoughX[i-1])

"""#### Outliers in InfeX"""

data_part2['InfeX'].dropna().sort_values(ascending=True).tail(2)

plt.boxplot(data_part2['InfeX'].dropna())

data_part2['InfeX_outliers_removed'] = data_part2['InfeX']
data_part2.loc[data_part2['InfeX'] > 106718.39, 'InfeX_outliers_removed'] = 106718.39

plt.boxplot(data_part2['InfeX_outliers_removed'].dropna())

pred_2019 = data_part1[data_part1['year']==2019]
actual_2019 = data_part2[data_part2['year']==2019]

min_mape = 100
min_mape_i = 0
i = 0
for [a,t,d,s,p,b,r] in grid_search_options_InfeX:
    i = i + 1

    if (t == None):
        model = ExponentialSmoothing(data_part2[data_part2['year'] < 2019]['InfeX_outliers_removed'],
                                     trend=t, seasonal=s, seasonal_periods=p, use_boxcox=b)
    else:
        model = ExponentialSmoothing(data_part2[data_part2['year'] < 2019]['InfeX_outliers_removed'],
                                     trend=t, damped=d, seasonal=s, seasonal_periods=p, use_boxcox=b)

    model_fit = model.fit(optimized=True, remove_bias=r, smoothing_level=a)

    pred_2019[f'InfeX_exp_smooth_{i}'] = model_fit.forecast(13)
    mape = np.round(np.mean(np.abs(actual_2019['InfeX'] - pred_2019[f'InfeX_exp_smooth_{i}']) / actual_2019['InfeX']) * 100, 2)
    if mape <= min_mape:
        min_mape = mape
        min_mape_i = i

plt.figure(figsize=(15,5))
plt.grid()
plt.title(f'InfeX Historical & Predicted Vs. Actual')

plt.plot(data_part1[data_part1['year'] == 2017]['month'], data_part1[data_part1['year'] == 2017]['InfeX'],
         label='Historical 2017', color='yellow')
plt.plot(data_part1[data_part1['year'] == 2018]['month'], data_part1[data_part1['year'] == 2018]['InfeX'],
         label='Historical 2018', color='yellow')
plt.plot(actual_2019['month'], actual_2019['InfeX'], label='Actual')

plt.plot(pred_2019['month'], pred_2019[f'InfeX_exp_smooth_{min_mape_i}'], label=f'Best MAPE = {min_mape}')

plt.legend()
print(grid_search_options_InfeX[i-1])

"""### 2020"""

data_part2[['Date', 'CoughX', 'CoughX - Average', 'CoughX - Exp Smoothing']].to_csv('coughx_2020.csv', index=False)

a,t,d,s,p,b,r = [0.8, 'mul', False, 'mul', 12, False, False]
model = ExponentialSmoothing(data_part2[data_part2['year'] < 2020]['CoughX'],
                             trend=t, seasonal=s, seasonal_periods=p, use_boxcox=b)

model_fit = model.fit(optimized=True, remove_bias=r, smoothing_level=a)

data_part2.loc[data_part2['year'] == 2020, 'CoughX - Exp Smoothing'] = model_fit.forecast(12).values

plt.figure(figsize=(13,5))
plt.title('Demand for CoughX')
plt.grid()
plt.plot(data_part2['Date'], data_part2['CoughX'], label='Historical Demand')
plt.plot(data_part2['Date'], data_part2['CoughX - Exp Smoothing'], label='Predicted Demand')
plt.plot(data_part2['Date'], data_part2['CoughX - Average'], label='Averaged Demand')

plt.legend()

data_part2[['Date', 'CoughX', 'CoughX - Average', 'CoughX - Exp Smoothing']].to_csv('coughx_2020.csv', index=False)

a,t,d,s,p,b,r = [0.8, None, None, None, 12, False, False]
model = ExponentialSmoothing(data_part2[data_part2['year'] < 2020]['InfeX_outliers_removed'],
                             trend=t, seasonal=s, seasonal_periods=p, use_boxcox=b)

model_fit = model.fit(optimized=True, remove_bias=r, smoothing_level=a)

data_part2.loc[data_part2['year'] == 2020, 'InfeX - Exp Smoothing'] = model_fit.forecast(12).values

plt.figure(figsize=(13,5))
plt.grid()
plt.title('Demand for InfeX')
plt.plot(data_part2['Date'], data_part2['InfeX'], label='Historical Demand')
plt.plot(data_part2['Date'], data_part2['InfeX - Exp Smoothing'], label='Predicted Demand')
plt.plot(data_part2['Date'], data_part2['InfeX - Avg'], label='Averaged Demand')

plt.legend()

data_part2[['Date', 'InfeX', 'InfeX - Avg', 'InfeX - Exp Smoothing']].to_csv('infex_2020.csv', index=False)





"""### APPENDIX

#### Grid search with 80:20 split
"""

min_mape = 100
min_mape_i = 0
i = 0

df_train = data_part2[data_part2['Date'] <= "2019-05-01"]
df_test = data_part2[(data_part2['Date'] > "2019-05-01") & (data_part2['year']==2019)]

for [a,t,d,s,p,b,r] in grid_search_options_CoughX:
    i = i + 1

    if (t == None):
        model = ExponentialSmoothing(df_train['CoughX'], trend=t, seasonal=s, seasonal_periods=p, use_boxcox=b)
    else:
        model = ExponentialSmoothing(df_train['CoughX'], trend=t, damped=d, seasonal=s, seasonal_periods=p, use_boxcox=b)

    model_fit = model.fit(optimized=True, remove_bias=r, smoothing_level=a)

    df_test[f'CoughX_exp_smooth_{i}'] = model_fit.forecast(len(df_test)+1)

    mape = np.round(np.mean(np.abs(df_test['CoughX'] - df_test[f'CoughX_exp_smooth_{i}']) / df_test['CoughX']) * 100, 2)

    if mape <= min_mape:
        min_mape = mape
        min_mape_i = i

plt.figure(figsize=(15,5))
plt.grid()
plt.title(f'CoughX Predicted Vs. Actual')

plt.plot(df_test['month'], df_test['CoughX'], label='Actual')
plt.plot(df_test['month'], df_test[f'CoughX_exp_smooth_{min_mape_i}'], label=f'Best MAPE = {min_mape}')

plt.legend()
print(grid_search_options_CoughX[i-1])

min_mape = 100
min_mape_i = 0
i = 0

df_train = data_part2[data_part2['Date'] <= "2019-05-01"]
df_test = data_part2[(data_part2['Date'] > "2019-05-01") & (data_part2['year']==2019)]

for [a,t,d,s,p,b,r] in grid_search_options_InfeX:
    i = i + 1

    if (t == None):
        model = ExponentialSmoothing(df_train['InfeX_outliers_removed'], trend=t, seasonal=s, seasonal_periods=p, use_boxcox=b)
    else:
        model = ExponentialSmoothing(df_train['InfeX_outliers_removed'], trend=t, damped=d, seasonal=s, seasonal_periods=p, use_boxcox=b)

    model_fit = model.fit(optimized=True, remove_bias=r, smoothing_level=a)

    df_test[f'InfeX_exp_smooth_{i}'] = model_fit.forecast(len(df_test)+1)

    mape = np.round(np.mean(np.abs(df_test['InfeX'] - df_test[f'InfeX_exp_smooth_{i}']) / df_test['InfeX']) * 100, 2)

    if mape <= min_mape:
        min_mape = mape
        min_mape_i = i

plt.figure(figsize=(15,5))
plt.grid()
plt.title(f'InfeX Predicted Vs. Actual')

plt.plot(df_test['month'], df_test['InfeX'], label='Actual')
plt.plot(df_test['month'], df_test[f'InfeX_exp_smooth_{min_mape_i}'], label=f'Best MAPE = {min_mape}')

plt.legend()
print(grid_search_options_InfeX[i-1])

"""### ARIMA"""

plot_acf(data_part2[data_part2['year'] < 2019]['CoughX'], lags=12)

model = ARIMA(data_part2[data_part2['year'] < 2019]['CoughX'], order=(8,0,2))
model_fit = model.fit()

print(model_fit.summary())

residuals = pd.DataFrame(model_fit.resid)
plt.scatter(residuals.index, residuals)

residuals.hist()

pred_2019['CoughX_ARIMA'] = model_fit.predict(start=25, end=36)
mape = np.round(np.mean(np.abs(actual_2019['CoughX'] - pred_2019['CoughX_ARIMA']) / actual_2019['CoughX']) * 100, 2)

mape

plt.figure(figsize=(15,5))
plt.grid()
plt.title(f'CoughX Historical & Predicted Vs. Actual')

plt.plot(data_part1[data_part1['year'] == 2017]['month'], data_part1[data_part1['year'] == 2017]['CoughX'],
         label='Historical 2017', color='yellow')
plt.plot(data_part1[data_part1['year'] == 2018]['month'], data_part1[data_part1['year'] == 2018]['CoughX'],
         label='Historical 2018', color='yellow')
plt.plot(actual_2019['month'], actual_2019['CoughX'], label='Actual')

plt.plot(pred_2019['month'], pred_2019['CoughX_ARIMA'], label=f'ARIMA MAPE = {mape}')

plt.legend()

plot_acf(data_part2[data_part2['year'] < 2019]['InfeX_outliers_removed'], lags=12)

model = ARIMA(data_part2[data_part2['year'] < 2019]['InfeX_outliers_removed'], order=(4,0,2))
model_fit = model.fit()

print(model_fit.summary())

residuals = pd.DataFrame(model_fit.resid)
plt.scatter(residuals.index, residuals)

residuals.hist()

pred_2019['InfeX_ARIMA'] = model_fit.predict(start=25, end=36)
mape = np.round(np.mean(np.abs(actual_2019['InfeX'] - pred_2019['InfeX_ARIMA']) / actual_2019['InfeX']) * 100, 2)

mape

plt.figure(figsize=(15,5))
plt.grid()
plt.title(f'InfeX Historical & Predicted Vs. Actual')

plt.plot(data_part1[data_part1['year'] == 2017]['month'], data_part1[data_part1['year'] == 2017]['InfeX'],
         label='Historical 2017', color='yellow')
plt.plot(data_part1[data_part1['year'] == 2018]['month'], data_part1[data_part1['year'] == 2018]['InfeX'],
         label='Historical 2018', color='yellow')
plt.plot(actual_2019['month'], actual_2019['InfeX'], label='Actual')

plt.plot(pred_2019['month'], pred_2019['InfeX_ARIMA'], label=f'ARIMA MAPE = {mape}')

plt.legend()







